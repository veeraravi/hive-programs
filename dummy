
# Define the schema for the nested structure
prescriber_rec_schema = StructType([
    StructField("pbr_dea_id", StringType(), True),
    StructField("pbr_npi", StringType(), True),
    StructField("pbr_first_nm", StringType(), True),
    StructField("pbr_mid_init_nm", StringType(), True),
    StructField("pbr_last_nm", StringType(), True),
])

# Define the outer schema
prescriber_outer_schema = StructType([
    StructField("d_prescriber_rec", prescriber_rec_schema, True),
])


# Define the schema for the nested structure
reject_code_rec_schema = StructType([
    StructField("dxf_sk", IntegerType(), True),
    StructField("rej_cd", StringType(), True),
    StructField("rej_cd_desc", StringType(), True),
    StructField("src_env_sk", StringType(), True)
])

# Define the outer schema
reject_code_outer_schema = StructType([
    StructField("1_reject_code_rec", reject_code_rec_schema, True),
])


#!/bin/bash

# Hive database name
DATABASE_NAME="your_database_name"

# Get the list of tables with names containing "_tmp"
TABLES=$(hive -e "USE $DATABASE_NAME; SHOW TABLES LIKE '*_tmp';")

# Iterate through the tables and get their paths
while read -r TABLE_NAME; do
  TABLE_PATH=$(hive -e "DESCRIBE EXTENDED $DATABASE_NAME.$TABLE_NAME;" | grep "Location:" | awk '{print $2}')
  echo "Table: $DATABASE_NAME.$TABLE_NAME, Path: $TABLE_PATH"
done <<< "$TABLES"

#!/bin/bash

# Hive database name
DATABASE_NAME="your_database_name"

# Create a temporary Hive script file
SCRIPT_FILE="/tmp/describe_script.hql"

# Get the list of tables with names containing "_tmp"
TABLES=$(hive -e "USE $DATABASE_NAME; SHOW TABLES LIKE '*_tmp';")

# Iterate through the tables and get their paths
while read -r TABLE_NAME; do
  # Generate a Hive script to describe the formatted table
  echo "USE $DATABASE_NAME;" > "$SCRIPT_FILE"
  echo "DESCRIBE FORMATTED $TABLE_NAME;" >> "$SCRIPT_FILE"

  # Run the script and capture the output
  TABLE_DESC=$(hive -f "$SCRIPT_FILE")

  # Extract the table path from the output
  TABLE_PATH=$(echo "$TABLE_DESC" | grep "Location:" | awk '{print $2}')
  echo "Table: $DATABASE_NAME.$TABLE_NAME, Path: $TABLE_PATH"
done <<< "$TABLES"

# Remove the temporary Hive script file
rm -f "$SCRIPT_FILE"


=============================================

#!/bin/bash

# Check if the required parameters are provided
if [ "$#" -ne 2 ]; then
  echo "Usage: $0 <hdfs_directory_path> <threshold_days>"
  exit 1
fi

# Set the HDFS directory path
HDFS_DIR="$1"

# Set the threshold time in seconds
THRESHOLD_DAYS="$2"
THRESHOLD_TIME=$((THRESHOLD_DAYS * 24 * 60 * 60))

# Get the current time in seconds since the epoch
CURRENT_TIME=$(date +%s)

# List files in the HDFS directory with their modification time and path
hadoop fs -ls -R "$HDFS_DIR" | while read -r line; do
  # Extract modification time and file path
  mod_time=$(echo "$line" | awk '{print $6, $7}')
  file_path=$(echo "$line" | awk '{print $8}')

  # Convert modification time to seconds since the epoch
  mod_time=$(date -d "$mod_time" +%s)

  # Calculate the age of the file in seconds
  age=$((CURRENT_TIME - mod_time))

  # Check if the file is older than the specified threshold
  if [ "$age" -gt "$THRESHOLD_TIME" ]; then
    echo "Deleting file: $file_path"
    # Uncomment the line below to actually delete the file
    # hadoop fs -rm "$file_path"
  fi
done









def process_abinitio_code(in_data):
    v_medlimit_service_seq_nbr = ""
    v_medlimit_dur_rsp_flg = ""
    v_medlimit_dur_srvc_cd_rsn = ""
    v_elm_c_e_resp_rsn_flg = ""
    v_elm_q_r_resp_rsn_flg = ""
    v_elm_w_aa_resp_rsn_flg = ""

    events = []  # Assuming events is a list that you want to populate

    for i in range(len(in_data.dur_rsp_cd_cntr)):
        if in_data.dur_rsp_cd_cntr[i] <= 10:
            events[in_data.dur_rsp_cd_cntr[i] - 1].resp = in_data.dur_rsp_flg[i]
            events[in_data.dur_rsp_cd_cntr[i] - 1].service = in_data.dur_srvc_nm[i]
            events[in_data.dur_rsp_cd_cntr[i] - 1].reason_service = in_data.dur_srvc_cd_rsn[i]

        if in_data.dur_srvc_nm[i] == 'MEDLIMIT':
            v_medlimit_service_seq_nbr += str(in_data.dur_rsp_cd_cntr[i]) + " "
            v_medlimit_dur_rsp_flg += str(in_data.dur_rsp_flg[i]) + " "
            v_medlimit_dur_srvc_cd_rsn += str(in_data.dur_srvc_cd_rsn[i]) + " "

            v_elm_c_e_resp_rsn_flg = "Y" if (in_data.dur_rsp_flg[i] == "s" and (in_data.dur_srvc_cd_rsn[i] == "HD" or in_data.dur_srvc_cd_rsn[i] == "HC")) else v_elm_c_e_resp_rsn_flg

            # 2022 condition "DUR Service Code Reason - HD or HC" changed to only "DUR_Service_Code_Reason - HD" now
            v_elm_q_r_resp_rsn_flg = "Y" if (in_data.dur_rsp_flg[i] == "H" and in_data.dur_srvc_cd_rsn[i] == "HD") else v_elm_q_r_resp_rsn_flg
            v_elm_w_aa_resp_rsn_flg = "Y" if (in_data.dur_rsp_flg[i] == "H" and in_data.dur_srvc_cd_rsn[i] == "MX") else v_elm_w_aa_resp_rsn_flg

    return v_medlimit_service_seq_nbr, v_medlimit_dur_rsp_flg, v_medlimit_dur_srvc_cd_rsn, v_elm_c_e_resp_rsn_flg, v_elm_q_r_resp_rsn_flg, v_elm_w_aa_resp_rsn_flg, events

# Example usage:
# Replace `your_input_data` with the actual data structure you have
result = process_abinitio_code(your_input_data)
# Access the results using the appropriate variables
print(result[0])  # v_medlimit_service_seq_nbr
print(result[1])  # v_medlimit_dur_rsp_flg
# ... and so on



from pyspark.sql import SparkSession
from pyspark.sql.functions import col, concat_ws

def process_abinitio_code(df):
    # Initializing variables
    v_medlimit_service_seq_nbr = ""
    v_medlimit_dur_rsp_flg = ""
    v_medlimit_dur_srvc_cd_rsn = ""
    v_elm_c_e_resp_rsn_flg = ""
    v_elm_q_r_resp_rsn_flg = ""
    v_elm_w_aa_resp_rsn_flg = ""

    # Assuming 'events' is a DataFrame that you want to manipulate
    # This assumes that the 'events' DataFrame already exists or you need to create it

    # Apply transformations to the DataFrame based on your logic
    df = df.withColumn('resp', col('dur_rsp_flg'))
    df = df.withColumn('service', col('dur_srvc_nm'))
    df = df.withColumn('reason_service', col('dur_srvc_cd_rsn'))

    # Apply filtering based on the condition dur_rsp_cd_cntr <= 10
    df_filtered = df.filter(col('dur_rsp_cd_cntr') <= 10)

    # Concatenate values for MEDLIMIT condition
    df_medlimit = df.filter(col('dur_srvc_nm') == 'MEDLIMIT')
    v_medlimit_service_seq_nbr = concat_ws(" ", df_medlimit.select('dur_rsp_cd_cntr').rdd.flatMap(lambda x: x))
    v_medlimit_dur_rsp_flg = concat_ws(" ", df_medlimit.select('dur_rsp_flg').rdd.flatMap(lambda x: x))
    v_medlimit_dur_srvc_cd_rsn = concat_ws(" ", df_medlimit.select('dur_srvc_cd_rsn').rdd.flatMap(lambda x: x))

    # Apply conditions for v_elm_c_e_resp_rsn_flg, v_elm_q_r_resp_rsn_flg, v_elm_w_aa_resp_rsn_flg
    df = df.withColumn('v_elm_c_e_resp_rsn_flg',
                       when((col('dur_rsp_flg') == 's') & ((col('dur_srvc_cd_rsn') == 'HD') | (col('dur_srvc_cd_rsn') == 'HC')), 'Y')
                       .otherwise(col('v_elm_c_e_resp_rsn_flg')))

    df = df.withColumn('v_elm_q_r_resp_rsn_flg',
                       when((col('dur_rsp_flg') == 'H') & (col('dur_srvc_cd_rsn') == 'HD'), 'Y')
                       .otherwise(col('v_elm_q_r_resp_rsn_flg')))

    df = df.withColumn('v_elm_w_aa_resp_rsn_flg',
                       when((col('dur_rsp_flg') == 'H') & (col('dur_srvc_cd_rsn') == 'MX'), 'Y')
                       .otherwise(col('v_elm_w_aa_resp_rsn_flg')))

    # Assuming 'events' is a DataFrame that you want to manipulate
    # This assumes that the 'events' DataFrame already exists or you need to create it
    events = df.select('resp', 'service', 'reason_service')

    return v_medlimit_service_seq_nbr, v_medlimit_dur_rsp_flg, v_medlimit_dur_srvc_cd_rsn, \
           v_elm_c_e_resp_rsn_flg, v_elm_q_r_resp_rsn_flg, v_elm_w_aa_resp_rsn_flg, events

# Example usage:
# Replace 'your_data_frame' with the actual DataFrame you have
result = process_abinitio_code(your_data_frame)
# Access the results using the appropriate variables
result[0].show()  # v_medlimit_service_seq_nbr
result[1].show()  # v_medlimit_dur_rsp_flg
# ... and so on











