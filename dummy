
# Define the schema for the nested structure
prescriber_rec_schema = StructType([
    StructField("pbr_dea_id", StringType(), True),
    StructField("pbr_npi", StringType(), True),
    StructField("pbr_first_nm", StringType(), True),
    StructField("pbr_mid_init_nm", StringType(), True),
    StructField("pbr_last_nm", StringType(), True),
])

# Define the outer schema
prescriber_outer_schema = StructType([
    StructField("d_prescriber_rec", prescriber_rec_schema, True),
])


# Define the schema for the nested structure
reject_code_rec_schema = StructType([
    StructField("dxf_sk", IntegerType(), True),
    StructField("rej_cd", StringType(), True),
    StructField("rej_cd_desc", StringType(), True),
    StructField("src_env_sk", StringType(), True)
])

# Define the outer schema
reject_code_outer_schema = StructType([
    StructField("1_reject_code_rec", reject_code_rec_schema, True),
])


#!/bin/bash

# Hive database name
DATABASE_NAME="your_database_name"

# Get the list of tables with names containing "_tmp"
TABLES=$(hive -e "USE $DATABASE_NAME; SHOW TABLES LIKE '*_tmp';")

# Iterate through the tables and get their paths
while read -r TABLE_NAME; do
  TABLE_PATH=$(hive -e "DESCRIBE EXTENDED $DATABASE_NAME.$TABLE_NAME;" | grep "Location:" | awk '{print $2}')
  echo "Table: $DATABASE_NAME.$TABLE_NAME, Path: $TABLE_PATH"
done <<< "$TABLES"

#!/bin/bash

# Hive database name
DATABASE_NAME="your_database_name"

# Create a temporary Hive script file
SCRIPT_FILE="/tmp/describe_script.hql"

# Get the list of tables with names containing "_tmp"
TABLES=$(hive -e "USE $DATABASE_NAME; SHOW TABLES LIKE '*_tmp';")

# Iterate through the tables and get their paths
while read -r TABLE_NAME; do
  # Generate a Hive script to describe the formatted table
  echo "USE $DATABASE_NAME;" > "$SCRIPT_FILE"
  echo "DESCRIBE FORMATTED $TABLE_NAME;" >> "$SCRIPT_FILE"

  # Run the script and capture the output
  TABLE_DESC=$(hive -f "$SCRIPT_FILE")

  # Extract the table path from the output
  TABLE_PATH=$(echo "$TABLE_DESC" | grep "Location:" | awk '{print $2}')
  echo "Table: $DATABASE_NAME.$TABLE_NAME, Path: $TABLE_PATH"
done <<< "$TABLES"

# Remove the temporary Hive script file
rm -f "$SCRIPT_FILE"


=============================================

#!/bin/bash

# Check if the required parameters are provided
if [ "$#" -ne 2 ]; then
  echo "Usage: $0 <hdfs_directory_path> <threshold_days>"
  exit 1
fi

# Set the HDFS directory path
HDFS_DIR="$1"

# Set the threshold time in seconds
THRESHOLD_DAYS="$2"
THRESHOLD_TIME=$((THRESHOLD_DAYS * 24 * 60 * 60))

# Get the current time in seconds since the epoch
CURRENT_TIME=$(date +%s)

# List files in the HDFS directory with their modification time and path
hadoop fs -ls -R "$HDFS_DIR" | while read -r line; do
  # Extract modification time and file path
  mod_time=$(echo "$line" | awk '{print $6, $7}')
  file_path=$(echo "$line" | awk '{print $8}')

  # Convert modification time to seconds since the epoch
  mod_time=$(date -d "$mod_time" +%s)

  # Calculate the age of the file in seconds
  age=$((CURRENT_TIME - mod_time))

  # Check if the file is older than the specified threshold
  if [ "$age" -gt "$THRESHOLD_TIME" ]; then
    echo "Deleting file: $file_path"
    # Uncomment the line below to actually delete the file
    # hadoop fs -rm "$file_path"
  fi
done





